title: "Joins and `tidyr` Homework"


<br>

The data for the joining tasks is from [Kaggle](https://www.kaggle.com/ananta/credit-card-data) and contains synthetic (fake) credit card information and transactions. The data for the `tidyr` tasks is also synthetic.

# MVP

## Joins


```{r}
# run libraries at start
library(tidyverse)
library(readxl)
library(skimr)
library(tidyr)
```


<br>
**Question 1**

Read in all 4 credit card transaction datasets and clean column names.

```{r}
#loading in data
card <- read_csv("data/CardBase.csv", show_col_types = FALSE)
customer <- read_csv("data/CustomerBase.csv", show_col_types = FALSE)
fraud <- read_csv("data/FraudBase.csv", show_col_types = FALSE)
transaction <- read_csv("data/TransactionBase.csv", show_col_types = FALSE)


view(card)
view(customer)
view(fraud)
view(transaction)
```



**Question 2**

Join the data containing card details and customer details by customer id, so that all records of card details and any matching records in customer details are kept. Before you run the code, think about how many rows you expect to see after joining.

Joining all records that match
Expec all cards (500) to have customer details added (but not all customer details will be in the card list)

```{r}
inner_join(card, customer, "Cust_ID")
```


**Question 3**

Join the data containing fraud details with transaction details so all rows of both tables are kept. What does the resulting row number tell you?

Joining all records and matching where possible
```{r}
full_join(fraud, transaction, "Transaction_ID")
```


**Question 4**

Join the data containing card details with transaction details so rows from the first which have matching ones in the second are returned, but only return rows in the first table once.

```{r}
colnames(card)
colnames(transaction)
```


```{r}
semi_join(card, transaction, c("Card_Number" = "Credit_Card_ID"))
```




## `tidyr`

**Question 5**

Read in `hat_observations` and separate `observation` into two columns, `hat_colour` and `hat_type`.

```{r}
#loading in data
hat <- read_csv("data/hat_observations.csv", show_col_types = FALSE)
view(hat)

hat_split <- hat %>% 
  separate(
    col = observation,
    into = c("hat_colour", "hat_type"),
    sep = "\\,"
  )

view(hat_split)

```



**Question 6**

Unite `day`, `month`, and `year` columns into a column called `date` using a suitable separator. Then find the date where the most berets were observed.

```{r}
hat_dates <- hat_split %>%
  unite("Date", day, month, year, sep = "/")

hat_dates
```


# Extension

## Joins

**Question 1**

Can you join all 4 datasets together so that you're left with a dataset that looks like below with **109 rows** and **12 columns**?

Potentially all those that have been flagged with fraud flag = 1

```{r}
dataset_picture <-
  full_join(card, customer, "Cust_ID") %>% 
  full_join(transaction, c("Card_Number" = "Credit_Card_ID")) %>% 
  inner_join(fraud, "Transaction_ID")
  
 dataset_picture 
```


![](images/all_joined.png)

## `tidyr`

**Question 2**

Read in `exam_scores` and transform it into long format with two new columns `exam_question` and `score`. Then, using `separate` and `select`, remove superfluous information from the values in `exam_question`


```{r}
#loading in data
exams <- read_csv("data/exam_scores.csv", show_col_types = FALSE)
view(exams)
```

pivot_long

```{r}
exams_long <- exams %>% 
  pivot_longer(
    cols = exam_Q1:exam_Q10,
    names_to = "exam_question",
    values_to = "score"
  )

view(exams_long)
```


```{r}

exams_split <- exams_long %>% 
  separate(
    col = exam_question,
    into = c("exam_text", "exam_question"),
    sep = "Q"
  ) %>% 
select(id, exam_question, score)

view(exams_split)

```



```{r}
colnames(exams)
```



